{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T19:39:13.964991Z",
     "start_time": "2021-10-10T19:39:13.859225Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from dataset import get_dataloader,EventData\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from models.gated_tpp import *\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models import sahp \n",
    "\n",
    "\n",
    "def load_data(name, dict_name):\n",
    "    with open(name, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='latin-1')\n",
    "        num_types = data['dim_process']\n",
    "        data = data[dict_name]\n",
    "        return data, int(num_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T23:47:05.371919Z",
     "start_time": "2021-10-09T23:47:05.360948Z"
    }
   },
   "outputs": [],
   "source": [
    "def power_law_kernel(t):  \n",
    "    \n",
    "    return 0.2 * (0.5 + t)**(-1.3)\n",
    "\n",
    "\n",
    "class rational_quadratic_kernel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_types, d_type, sigma=1, p=1, alpha=1,lengthscale = 1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_type = d_type\n",
    "        self.num_types = num_types\n",
    "        self.norm = p\n",
    "        # self.sigma = sigma\n",
    "        self.param_loss = 0\n",
    "        self.scores = None\n",
    "        self.alpha =alpha\n",
    "        \"\"\"\n",
    "        If the model is 1-D we still need the type embedding as an input and train a linear layer followed by softplus\n",
    "        to make sure the length_scale parameter is positive. Adding a parameter followed by a sigmoid creates a non leaf\n",
    "        tensor and there for doesn't work.\n",
    "        \"\"\"\n",
    "\n",
    "        if num_types == 1:\n",
    "\n",
    "\n",
    "            self.lengthscale = torch.nn.Parameter(torch.randn(1))\n",
    "            self.base_intensity = 0.1\n",
    "            self.sigma = torch.nn.Parameter(torch.randn(1))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        d = torch.abs(x[0] - x[1])**self.norm\n",
    "        \n",
    "        lengthscale = F.softplus(self.lengthscale,beta = 5)\n",
    "        sigma = F.softplus(self.sigma,beta = 1)\n",
    "        base_intensity = F.softplus(self.base_intensity,beta = 1)\n",
    "        \n",
    "        sigma= self.sigma\n",
    "        lengthscale = self.lengthscale\n",
    "        alpha = 0.6\n",
    "#         self.base_intensity = 0.1\n",
    "\n",
    "        self.scores = (sigma ** 2) * (1 + (d ** 2) / (alpha * lengthscale ** 2)) ** (-alpha)\n",
    "\n",
    "        return self.scores\n",
    "    def params(self, type_emb):\n",
    "\n",
    "        params = []\n",
    "        for space in type_emb[1:]:\n",
    "            lengthscale = self.lengthscale(space).item()\n",
    "            # alpha = self.alpha(space).item()\n",
    "            alpha = self.alpha.item()\n",
    "\n",
    "            params.append({'length_scale': lengthscale, 'alpha': alpha, 'sigma': self.sigma, 'Norm-P': self.norm})\n",
    "\n",
    "        return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T07:44:08.214257Z",
     "start_time": "2021-10-06T07:44:06.560448Z"
    }
   },
   "outputs": [],
   "source": [
    "data = '../data/simulated/power_hawkes/'\n",
    "batch_size = 1\n",
    "\n",
    "kernel = rational_quadratic_kernel(1,1)\n",
    "\n",
    "train_data, num_types = load_data(data + 'train.pkl', 'train')\n",
    "dev_data, _ = load_data(data + 'dev.pkl', 'dev')\n",
    "test_data, _ = load_data(data + 'test.pkl', 'test')\n",
    "t_max = 1\n",
    "\n",
    "trainloader = get_dataloader(train_data, 20, shuffle=False,t_max =t_max)\n",
    "testloader = get_dataloader(test_data,40, shuffle=False,t_max = t_max)\n",
    "valloader = get_dataloader(dev_data,40, shuffle=False,t_max =t_max)\n",
    "\n",
    "\n",
    "valid_events = 0\n",
    "test_events = 0\n",
    "train_events = 0\n",
    "for seq in valloader.dataset.event_type:\n",
    "    valid_events += len(seq)\n",
    "for seq in trainloader.dataset.event_type:\n",
    "    train_events += len(seq)\n",
    "for seq in testloader.dataset.event_type:\n",
    "    test_events  += len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T02:50:03.327574Z",
     "start_time": "2021-10-06T02:48:46.462317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, NLL:2.603101\n",
      "Epoch:1, NLL:2.593400\n",
      "Epoch:2, NLL:2.580921\n",
      "Epoch:3, NLL:2.566257\n",
      "Epoch:4, NLL:2.549721\n",
      "Epoch:5, NLL:2.531621\n",
      "Epoch:6, NLL:2.512281\n",
      "Epoch:7, NLL:2.492025\n",
      "Epoch:8, NLL:2.471168\n",
      "Epoch:9, NLL:2.450005\n",
      "Epoch:10, NLL:2.428809\n",
      "Epoch:11, NLL:2.407821\n",
      "Epoch:12, NLL:2.387255\n",
      "Epoch:13, NLL:2.367293\n",
      "Epoch:14, NLL:2.348092\n",
      "Epoch:15, NLL:2.329784\n",
      "Epoch:16, NLL:2.312474\n",
      "Epoch:17, NLL:2.296250\n",
      "Epoch:18, NLL:2.281180\n",
      "Epoch:19, NLL:2.267317\n",
      "Epoch:20, NLL:2.254696\n",
      "Epoch:21, NLL:2.243344\n",
      "Epoch:22, NLL:2.233275\n",
      "Epoch:23, NLL:2.224494\n",
      "Epoch:24, NLL:2.216997\n",
      "Epoch:25, NLL:2.210773\n",
      "Epoch:26, NLL:2.205806\n",
      "Epoch:27, NLL:2.202072\n",
      "Epoch:28, NLL:2.199543\n",
      "Epoch:29, NLL:2.198184\n",
      "Epoch:30, NLL:2.197961\n",
      "Epoch:31, NLL:2.198832\n",
      "Epoch:32, NLL:2.200749\n",
      "Epoch:33, NLL:2.203665\n",
      "Epoch:34, NLL:2.207524\n",
      "Epoch:35, NLL:2.212272\n",
      "Epoch:36, NLL:2.217844\n",
      "Epoch:37, NLL:2.224177\n",
      "Epoch:38, NLL:2.231198\n",
      "Epoch:39, NLL:2.238831\n",
      "Epoch:40, NLL:2.246998\n",
      "Epoch:41, NLL:2.255607\n",
      "Epoch:42, NLL:2.264566\n",
      "Epoch:43, NLL:2.273775\n",
      "Epoch:44, NLL:2.283121\n",
      "Epoch:45, NLL:2.292488\n",
      "Epoch:46, NLL:2.301747\n",
      "Epoch:47, NLL:2.310760\n",
      "Epoch:48, NLL:2.319376\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-927-c4accc8bceda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mintensities\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0msubsequent_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_subsequent_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mintensities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintensities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubsequent_mask\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Research\\TPP\\gated_kernel_tpp\\models\\gated_tpp.py\u001b[0m in \u001b[0;36mget_subsequent_mask\u001b[1;34m(seq)\u001b[0m\n\u001b[0;32m    269\u001b[0m         torch.ones((len_s, len_s), device=seq.device, dtype=torch.uint8), diagonal=1)\n\u001b[0;32m    270\u001b[0m     \u001b[0msubsequent_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubsequent_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msz_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# b x ls x ls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m     \u001b[0msubsequent_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msubsequent_mask\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msubsequent_mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda x: x.requires_grad, kernel.parameters()),\n",
    "                      0.0001, betas=(0.9, 0.999), eps=1e-05, weight_decay=0.0)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "\n",
    "losses = []\n",
    "params = []\n",
    "for epoch in range(100):\n",
    "    epoch_loss= 0\n",
    "\n",
    "    for batch in trainloader:\n",
    "        event_time, arrival_time, event_type, _ = map(lambda x: x.to('cpu'), batch)\n",
    "\n",
    "        lengths = (event_type != 0).sum(-1).to('cpu')\n",
    "        xt_bar = event_time.unsqueeze(1). \\\n",
    "            expand(event_time.size(0), event_time.size(1), event_time.size(1))\n",
    "        xt = xt_bar.transpose(1, 2)\n",
    "        scores = kernel((xt_bar,xt))\n",
    "\n",
    "\n",
    "\n",
    "        n_batch = xt.size()[0]\n",
    "        length= xt.size()[1]\n",
    "        samples = 1000\n",
    "\n",
    "        ## Log Sum Intensities\n",
    "\n",
    "        scores_0 = kernel((torch.ones(n_batch,length),torch.ones(n_batch,length)))\n",
    "        intensities =scores \n",
    "\n",
    "        subsequent_mask=get_subsequent_mask(event_type)\n",
    "        intensities = intensities.masked_fill_(subsequent_mask == 0, value=0)\n",
    "\n",
    "        sample_intensities = intensities.sum(-1)-scores_0+kernel.base_intensity\n",
    "        log_sum_intensities =nn.utils.rnn.pack_padded_sequence(sample_intensities.T, lengths - 1, enforce_sorted=False)[0].log().sum(-1)\n",
    "\n",
    "\n",
    "        ## Non Event Intensities  MC Integration\n",
    "\n",
    "        t_start = event_time[:,0]\n",
    "        t_end =  event_time.max(-1)[0]\n",
    "        constant_part = (sample_intensities[:,:-1]*arrival_time[:,1:]).sum(-1)\n",
    "\n",
    "\n",
    "        mc_sample_values = (t_start.unsqueeze(-1)+torch.rand((n_batch,samples ))*(t_end -t_start).unsqueeze(-1))\n",
    "        v = kernel((mc_sample_values,torch.zeros(mc_sample_values.size()))).mean(-1)\n",
    "\n",
    "        non_event_intensity = (constant_part+functional_part +t_start*kernel.base_intensity).sum(-1)\n",
    "\n",
    "        batch_loss = -(log_sum_intensities - non_event_intensity)\n",
    "\n",
    "        epoch_loss+=batch_loss\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    epoch_loss = (epoch_loss/train_events).item()\n",
    "    print(f'Epoch:{epoch}, NLL:{epoch_loss:.6f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T02:50:21.668789Z",
     "start_time": "2021-10-06T02:50:21.659814Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4511], grad_fn=<SoftplusBackward>)"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softplus(kernel.sigma,beta = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T02:50:29.420963Z",
     "start_time": "2021-10-06T02:50:29.405007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2789], grad_fn=<SoftplusBackward>)"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softplus(kernel.lengthscale,beta = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T02:30:55.200571Z",
     "start_time": "2021-10-07T02:30:51.709411Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class rational_quadratic_kernel(nn.Module):\n",
    "\n",
    "    def __init__(self,sigma=1,alpha=1,lengthscale = 1.0,base_intensity =0.2):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        If the model is 1-D we still need the type embedding as an input and train a linear layer followed by softplus\n",
    "        to make sure the length_scale parameter is positive. Adding a parameter followed by a sigmoid creates a non leaf\n",
    "        tensor and there for doesn't work.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.lengthscale = lengthscale\n",
    "        self.base_intensity = base_intensity\n",
    "        self.sigma = sigma\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        d = torch.abs(x[0] - x[1])\n",
    "        self.scores = 0.2 * (0.5 +d)**(-1.3)\n",
    "\n",
    "#         self.scores = (self.sigma ** 2) * (1 + (d ** 2) / (self.alpha * self.lengthscale ** 2)) ** (-self.alpha)\n",
    "\n",
    "        return self.scores\n",
    "    def params(self, type_emb):\n",
    "\n",
    "        params = []\n",
    "        for space in type_emb[1:]:\n",
    "            lengthscale = self.lengthscale(space).item()\n",
    "            # alpha = self.alpha(space).item()\n",
    "            alpha = self.alpha.item()\n",
    "\n",
    "            params.append({'length_scale': lengthscale, 'alpha': alpha, 'sigma': self.sigma, 'Norm-P': self.norm})\n",
    "\n",
    "        return params\n",
    "\n",
    "torch.manual_seed(42)\n",
    "epoch_losses = []\n",
    "sigmas = np.linspace(0.1,1.2,1)\n",
    "for sigma in sigmas:\n",
    "    kernel = rational_quadratic_kernel(sigma = 0.7, lengthscale=sigma,alpha = 0.6, base_intensity= 0.2)\n",
    "    epoch_loss = 0\n",
    "    for batch in trainloader:\n",
    "        event_time, arrival_time, event_type, _ = map(lambda x: x.to('cpu'), batch)\n",
    "\n",
    "        lengths = (event_type != 0).sum(-1).to('cpu')\n",
    "        xt_bar = event_time.unsqueeze(1). \\\n",
    "            expand(event_time.size(0), event_time.size(1), event_time.size(1))\n",
    "        xt = xt_bar.transpose(1, 2)\n",
    "        scores = kernel((xt_bar,xt))\n",
    "\n",
    "\n",
    "\n",
    "        n_batch = xt.size()[0]\n",
    "        length= xt.size()[1]\n",
    "#         samples = 1000\n",
    "\n",
    "        ## Log Sum Intensities\n",
    "\n",
    "        scores_0 = kernel((torch.ones(n_batch,length),torch.ones(n_batch,length)))\n",
    "        intensities =scores \n",
    "\n",
    "        subsequent_mask=get_subsequent_mask(event_type)\n",
    "        intensities = intensities.masked_fill_(subsequent_mask == 0, value=0)\n",
    "\n",
    "        sample_intensities = intensities.sum(-1)-scores_0+kernel.base_intensity\n",
    "        \n",
    "#         sample_intensities = intensities.sum(-1)-scores_0+0.1\n",
    "\n",
    "        \n",
    "\n",
    "        log_sum_intensities =nn.utils.rnn.pack_padded_sequence(sample_intensities.T, lengths - 1, enforce_sorted=False)[0].log().sum(-1)\n",
    "\n",
    "\n",
    "        ## Non Event Intensities  MC Integration\n",
    "\n",
    "#         t_start = event_time[:,0]\n",
    "#         t_end =  event_time.max(-1)[0]\n",
    "\n",
    "#         constant_part = (sample_intensities[:,:-1]*arrival_time[:,1:]).sum(-1)\n",
    "\n",
    "\n",
    "#         mc_sample_values = (t_start.unsqueeze(-1)+torch.rand((n_batch,samples ))*(t_end -t_start).unsqueeze(-1))\n",
    "#         v = kernel((mc_sample_values,torch.zeros(mc_sample_values.size()))).mean(-1)\n",
    "\n",
    "#         non_event_intensity = (constant_part+functional_part ).sum(-1)\n",
    "\n",
    "\n",
    "        sample_arrival_time = arrival_time[:,1:]\n",
    "        sample_event_time = event_time[:,:-1]\n",
    "        n_mc_sample = 10\n",
    "        n_batch = sample_arrival_time.size(0)\n",
    "        n_t = sample_arrival_time.size(1)\n",
    "\n",
    "        mc_values = torch.rand((n_batch,n_t,n_mc_sample ))*sample_arrival_time.unsqueeze(-1)+sample_event_time.unsqueeze(-1)\n",
    "\n",
    "        xt_event= sample_event_time.unsqueeze(-1)*torch.ones((n_batch,n_t,n_mc_sample ))\n",
    "        xt_bar = xt_event.unsqueeze(1).expand(xt_event.size(0), xt_event.size(1), xt_event.size(1), xt_event.size(2))\n",
    "        xt = xt_bar.transpose(1, 2)\n",
    "\n",
    "        xt_sample = mc_values\n",
    "        xt_sample_bar = xt_sample.unsqueeze(1).expand(xt_sample.size(0), xt_sample.size(1), xt_sample.size(1), xt_sample.size(2))\n",
    "        xt_sample = xt_sample_bar.transpose(1, 2)\n",
    "\n",
    "        mc_mask = get_subsequent_mask(event_type[:,1:])\n",
    "\n",
    "        non_event_intensity = kernel((xt_bar, xt_sample)).mean(-1)\n",
    "        non_event_intensity = non_event_intensity.masked_fill_(mc_mask == 0, value=0)\n",
    "        non_event_intensity = non_event_intensity.sum(-1)+kernel.base_intensity\n",
    "\n",
    "        non_event_intensities =nn.utils.rnn.pack_padded_sequence(non_event_intensity.T, lengths - 1, enforce_sorted=False)[0].sum(-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        batch_loss = -(log_sum_intensities - non_event_intensities)\n",
    "\n",
    "        epoch_loss+=batch_loss\n",
    "\n",
    "\n",
    "\n",
    "    epoch_loss = (epoch_loss/train_events).item()\n",
    "\n",
    "    epoch_losses.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:55:00.533961Z",
     "start_time": "2021-10-06T04:55:00.519996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.3623)"
      ]
     },
     "execution_count": 1273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_event_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:55:01.551428Z",
     "start_time": "2021-10-06T04:55:01.544447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.418138861656189]"
      ]
     },
     "execution_count": 1274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:53:01.409956Z",
     "start_time": "2021-10-06T04:53:01.398985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7872405052185059]"
      ]
     },
     "execution_count": 1262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:55:06.724351Z",
     "start_time": "2021-10-06T04:55:06.704413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.418138861656189]"
      ]
     },
     "execution_count": 1275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T02:59:12.485773Z",
     "start_time": "2021-10-06T02:59:12.477764Z"
    }
   },
   "outputs": [],
   "source": [
    "def kernel_fun(t):\n",
    "    return (kernel.sigma ** 2) * (1 + (t ** 2) / (kernel.alpha * kernel.lengthscale ** 2)) ** (-kernel.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:00:53.835648Z",
     "start_time": "2021-10-06T03:00:53.821643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1381845464077335"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        ## Non Event Intensities  MC Integration\n",
    "\n",
    "        t_start = event_time[:,0]\n",
    "        t_end =  event_time.max(-1)[0]\n",
    "\n",
    "        constant_part = (sample_intensities[:,:-1]*arrival_time[:,1:]).sum(-1)\n",
    "\n",
    "\n",
    "        mc_sample_values = (t_start.unsqueeze(-1)+torch.rand((n_batch,samples ))*(t_end -t_start).unsqueeze(-1))\n",
    "        v = kernel((mc_sample_values,torch.zeros(mc_sample_values.size()))).mean(-1)\n",
    "\n",
    "        non_event_intensity = (constant_part+functional_part ).sum(-1)\n",
    "\n",
    "        batch_loss = -(log_sum_intensities - non_event_intensity)\n",
    "\n",
    "        epoch_loss+=batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:08:38.043327Z",
     "start_time": "2021-10-06T04:08:38.029329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 1077,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:34:12.827763Z",
     "start_time": "2021-10-06T04:34:12.796849Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_arrival_time = arrival_time[:,1:]\n",
    "sample_event_time = event_time[:,:-1]\n",
    "n_mc_sample = 10\n",
    "n_batch = sample_arrival_time.size(0)\n",
    "n_t = sample_arrival_time.size(1)\n",
    "\n",
    "mc_values = torch.rand((n_batch,n_t,n_mc_sample ))*sample_arrival_time.unsqueeze(-1)+sample_event_time.unsqueeze(-1)\n",
    "\n",
    "xt_event= sample_event_time.unsqueeze(-1)*torch.ones((n_batch,n_t,n_mc_sample ))\n",
    "xt_bar = xt_event.unsqueeze(1).expand(xt_event.size(0), xt_event.size(1), xt_event.size(1), xt_event.size(2))\n",
    "xt = xt_bar.transpose(1, 2)\n",
    "\n",
    "xt_sample = mc_values\n",
    "xt_sample_bar = xt_sample.unsqueeze(1).expand(xt_sample.size(0), xt_sample.size(1), xt_sample.size(1), xt_sample.size(2))\n",
    "xt_sample = xt_sample_bar.transpose(1, 2)\n",
    "\n",
    "mc_mask = get_subsequent_mask(event_type[:,1:])\n",
    "\n",
    "non_event_intensity = kernel((xt_bar, xt_sample)).mean(-1)\n",
    "non_event_intensity = non_event_intensity.masked_fill_(mc_mask == 0, value=0)\n",
    "non_event_intensity = non_event_intensity.sum(-1)+kernel.base_intensity\n",
    "\n",
    "non_event_intensities =nn.utils.rnn.pack_padded_sequence(non_event_intensity.T, lengths - 1, enforce_sorted=False)[0].sum(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:34:08.291410Z",
     "start_time": "2021-10-06T04:34:08.277448Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:33:06.608309Z",
     "start_time": "2021-10-06T04:33:06.590358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(81.1080)"
      ]
     },
     "execution_count": 1193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_event_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:34:04.955422Z",
     "start_time": "2021-10-06T04:34:04.941494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1517, 0.1335, 0.2046, 0.5943, 0.1477, 0.5201, 0.1689, 0.2538, 0.4648,\n",
       "        0.3040, 0.2520, 0.2212, 0.2082, 0.1657, 0.1333, 0.3494, 0.2570, 0.2208,\n",
       "        0.2709, 0.5591, 0.4598, 0.1407, 0.1754, 0.2374, 0.3045, 0.2065, 0.1368,\n",
       "        0.1416, 0.1299, 0.1510, 0.5377, 0.1482, 0.2143, 0.2060, 0.2244, 0.1943,\n",
       "        0.1834, 0.1345, 0.1397, 0.3541, 0.2485, 0.1854, 0.1658, 0.1808, 0.2869,\n",
       "        0.2839, 0.2033, 0.5245, 0.5232, 0.1896, 0.1693, 0.2772, 0.5179, 0.3203,\n",
       "        0.2159, 0.2372, 0.2343, 0.3975, 0.2719, 0.3615, 0.2535, 0.4384, 0.3177,\n",
       "        0.2466, 0.5769, 0.2786, 0.5765, 0.4167, 0.2001, 0.1342, 0.2018, 0.5632,\n",
       "        0.2606, 0.4913, 0.6287, 0.3222, 0.6497, 0.5851, 0.7569, 0.2629, 0.2645,\n",
       "        0.2704, 0.2155, 0.2781, 0.4020, 0.4314, 0.2010, 0.4162, 0.6847, 1.0569,\n",
       "        0.8429, 0.9096, 0.6376, 0.3916, 0.6885, 0.2481, 0.5883, 0.2677])"
      ]
     },
     "execution_count": 1200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_event_intensity[0][:98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:23:31.734083Z",
     "start_time": "2021-10-06T04:23:31.726104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.258316616710772"
      ]
     },
     "execution_count": 1152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_fun(21.6880- 21.1532) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:33:51.480288Z",
     "start_time": "2021-10-06T04:33:51.469317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 1197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:32:26.780312Z",
     "start_time": "2021-10-06T04:32:26.766317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 99])"
      ]
     },
     "execution_count": 1191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:06:04.665147Z",
     "start_time": "2021-10-06T04:06:04.651212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11711388426216773"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_fun(6.328099999999999)+0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:15:14.870295Z",
     "start_time": "2021-10-06T04:15:14.851346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.745199999999997"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21.6880 -1.9428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:05:02.238630Z",
     "start_time": "2021-10-06T04:05:02.220687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  8.2709],\n",
       "         [ 20.9551],\n",
       "         [ 21.6880],\n",
       "         [ 30.6744],\n",
       "         [ 33.2481],\n",
       "         [ 34.3715],\n",
       "         [ 34.5948],\n",
       "         [ 47.2411],\n",
       "         [ 55.4900],\n",
       "         [ 56.2789],\n",
       "         [ 57.7469],\n",
       "         [ 63.2879],\n",
       "         [ 67.9797],\n",
       "         [ 68.6348],\n",
       "         [ 70.2827],\n",
       "         [ 72.5266],\n",
       "         [ 77.2246],\n",
       "         [ 84.5279],\n",
       "         [ 91.0509],\n",
       "         [ 92.9189],\n",
       "         [ 92.9970],\n",
       "         [ 93.2972],\n",
       "         [ 95.5436],\n",
       "         [ 99.8411],\n",
       "         [109.1335],\n",
       "         [109.7105],\n",
       "         [115.0233],\n",
       "         [123.4831],\n",
       "         [133.3540],\n",
       "         [150.4730],\n",
       "         [156.3795],\n",
       "         [162.2316],\n",
       "         [168.2349],\n",
       "         [168.3637],\n",
       "         [170.9719],\n",
       "         [184.7617],\n",
       "         [188.2206],\n",
       "         [190.9484],\n",
       "         [194.9506],\n",
       "         [196.1874]]])"
      ]
     },
     "execution_count": 1061,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T04:00:58.317201Z",
     "start_time": "2021-10-06T04:00:58.299252Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T03:56:46.117980Z",
     "start_time": "2021-10-06T03:56:46.107974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.9428,  17.4422,  21.1532,  21.9291,  33.2375,  33.4575,  34.4283,\n",
       "          34.7124,  53.4867,  56.0763,  56.9533,  61.1035,  67.6659,  68.6015,\n",
       "          68.9651,  71.2981,  76.6498,  77.9613,  85.5929,  92.5619,  92.9643,\n",
       "          93.0787,  93.9720,  98.9322, 108.3831, 109.2280, 109.9768, 120.7993,\n",
       "         133.1943, 142.5763, 156.1926, 156.6497, 168.1940, 168.2588, 168.3697,\n",
       "         178.2014, 185.2074, 188.7799, 192.2796, 196.0970]])"
      ]
     },
     "execution_count": 1042,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_event_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T02:56:59.453604Z",
     "start_time": "2021-10-06T02:56:59.442632Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5499e+00, 3.9282e-01, 1.0618e-01, 3.5778e+00, 2.7426e-02, 5.2278e-01,\n",
       "         1.1106e-01, 1.3293e+01, 3.2679e-01, 1.5128e-01, 1.3376e+00, 1.2020e+00,\n",
       "         1.4517e-01, 1.1083e-01, 1.3833e+00, 1.4800e+00, 2.4672e-01, 2.1615e+00,\n",
       "         1.1689e+00, 6.3755e-02, 5.4035e-02, 7.9269e-01, 2.7650e+00, 2.0513e+00,\n",
       "         1.3761e-01, 2.4785e-01, 4.7237e+00, 1.9986e+00, 1.3526e+00, 1.9496e+00,\n",
       "         6.1524e-02, 4.8983e+00, 9.1617e-03, 6.9108e-02, 1.0288e+01, 1.1118e+00,\n",
       "         5.5501e-01, 6.2436e-01, 7.1769e-01, 4.0144e-01]])"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_intensities[:,:-1]*arrival_time[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T02:56:07.129468Z",
     "start_time": "2021-10-06T02:56:07.109522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2566.7708)"
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_event_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T02:54:01.231325Z",
     "start_time": "2021-10-06T02:54:01.212377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05 , 0.125, 0.2  , 0.275, 0.35 , 0.425, 0.5  ])"
      ]
     },
     "execution_count": 945,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T02:52:40.906540Z",
     "start_time": "2021-10-06T02:52:40.889583Z"
    }
   },
   "source": [
    "## Learning Params for Exponential Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T09:11:35.558428Z",
     "start_time": "2021-10-06T09:11:34.774372Z"
    }
   },
   "outputs": [],
   "source": [
    "data = '../data/simulated/power_hawkes/'\n",
    "batch_size = 1\n",
    "\n",
    "# kernel = rational_quadratic_kernel(1,1)\n",
    "\n",
    "train_data, num_types = load_data(data + 'train.pkl', 'train')\n",
    "dev_data, _ = load_data(data + 'dev.pkl', 'dev')\n",
    "test_data, _ = load_data(data + 'test.pkl', 'test')\n",
    "t_max = 1\n",
    "\n",
    "trainloader = get_dataloader(train_data, 20, shuffle=False,t_max =t_max)\n",
    "testloader = get_dataloader(test_data,40, shuffle=False,t_max = t_max)\n",
    "valloader = get_dataloader(dev_data,40, shuffle=False,t_max =t_max)\n",
    "\n",
    "\n",
    "valid_events = 0\n",
    "test_events = 0\n",
    "train_events = 0\n",
    "for seq in valloader.dataset.event_type:\n",
    "    valid_events += len(seq)\n",
    "for seq in trainloader.dataset.event_type:\n",
    "    train_events += len(seq)\n",
    "for seq in testloader.dataset.event_type:\n",
    "    test_events  += len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T21:01:01.372639Z",
     "start_time": "2021-10-06T21:00:42.072358Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yamac\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, NLL:2.818700\n",
      "Lengthscale:0.380243\n",
      "Sigma:0.823427\n",
      "Base_intensity:0.144401\n",
      "\n",
      "Epoch:1, NLL:2.802478\n",
      "Lengthscale:0.392188\n",
      "Sigma:0.830846\n",
      "Base_intensity:0.134962\n",
      "\n",
      "Epoch:2, NLL:2.788753\n",
      "Lengthscale:0.404574\n",
      "Sigma:0.838354\n",
      "Base_intensity:0.126048\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-abf0c95afc1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    116\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m                    eps=group['eps'])\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class exponential_kernel(nn.Module):\n",
    "\n",
    "    def __init__(self,sigma=1,alpha=1,lengthscale = 1.0,base_intensity =0.2):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        If the model is 1-D we still need the type embedding as an input and train a linear layer followed by softplus\n",
    "        to make sure the length_scale parameter is positive. Adding a parameter followed by a sigmoid creates a non leaf\n",
    "        tensor and there for doesn't work.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.lengthscale = torch.nn.Parameter(torch.randn(1))\n",
    "        self.base_intensity = torch.nn.Parameter(torch.randn(1))\n",
    "        self.sigma = torch.nn.Parameter(torch.randn(1))\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        base_intensity = F.softplus(self.base_intensity,beta = 10)\n",
    "        lengthscale = F.softplus(self.lengthscale,beta = 5)\n",
    "        sigma = F.softplus(self.sigma,beta =5)\n",
    "        \n",
    "        \n",
    "        d = torch.abs(x[0] - x[1])\n",
    "        self.scores = sigma*torch.exp(-d/lengthscale)\n",
    "        \n",
    "        \n",
    "\n",
    "#         self.scores = (self.sigma ** 2) * (1 + (d ** 2) / (self.alpha * self.lengthscale ** 2)) ** (-self.alpha)\n",
    "\n",
    "        return self.scores\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "epoch_losses = []\n",
    "\n",
    "\n",
    "kernel = exponential_kernel(sigma = 0.6, lengthscale=0.7, base_intensity= 0.1)\n",
    "optimizer = optim.Adam(filter(lambda x: x.requires_grad, kernel.parameters()),\n",
    "                      0.0000, betas=(0.9, 0.999), eps=1e-05, weight_decay=0.0)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for batch in trainloader:\n",
    "        event_time, arrival_time, event_type, _ = map(lambda x: x.to('cpu'), batch)\n",
    "\n",
    "        lengths = (event_type != 0).sum(-1).to('cpu')\n",
    "        xt_bar = event_time.unsqueeze(1). \\\n",
    "            expand(event_time.size(0), event_time.size(1), event_time.size(1))\n",
    "        xt = xt_bar.transpose(1, 2)\n",
    "        scores = kernel((xt_bar,xt))\n",
    "\n",
    "\n",
    "\n",
    "        n_batch = xt.size()[0]\n",
    "        length= xt.size()[1]\n",
    "    #         samples = 1000\n",
    "    \n",
    "        sigma = F.softplus(kernel.sigma,beta = 1)\n",
    "        base_intensity = F.softplus(kernel.base_intensity,beta = 10)\n",
    "        lengthscale = F.softplus(kernel.lengthscale,beta = 5)\n",
    "\n",
    "        ## Log Sum Intensities\n",
    "\n",
    "        scores_0 = kernel((torch.ones(n_batch,length),torch.ones(n_batch,length)))\n",
    "        intensities =scores \n",
    "\n",
    "        subsequent_mask=get_subsequent_mask(event_type)\n",
    "        intensities = intensities.masked_fill_(subsequent_mask == 0, value=0)\n",
    "\n",
    "        sample_intensities = intensities.sum(-1)-scores_0+base_intensity\n",
    "\n",
    "\n",
    "        log_sum_intensities =nn.utils.rnn.pack_padded_sequence(sample_intensities.T, lengths - 1, enforce_sorted=False)[0].log().sum(-1)\n",
    "\n",
    "\n",
    "        ## Non Event Intensities Integral\n",
    "\n",
    "        t_start = event_time[:,0]\n",
    "        t_end =  event_time.max(-1)[0]\n",
    "\n",
    "        constant_part = (sample_intensities[:,:-1]*arrival_time[:,1:]).sum(-1)\n",
    "        functional_part =(sigma*arrival_time[:,1:]*torch.exp(-arrival_time[:,1:]/lengthscale)).sum(-1)\n",
    "        non_event_intensities = constant_part+functional_part +torch.abs((t_start - t_end)*base_intensity)\n",
    "\n",
    "\n",
    "        batch_loss = -(log_sum_intensities - non_event_intensities.sum())\n",
    "        epoch_loss+=batch_loss\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    epoch_loss = (epoch_loss/train_events).item()\n",
    "    print(f'Epoch:{epoch}, NLL:{epoch_loss:.6f}')\n",
    "    print(f'Lengthscale:{lengthscale.item():.6f}')\n",
    "    print(f'Sigma:{sigma.item():.6f}')\n",
    "    print(f'Base_intensity:{base_intensity.item():.6f}\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "    epoch_losses.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from Sinusoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:20:06.406384Z",
     "start_time": "2021-10-09T22:20:05.586356Z"
    }
   },
   "outputs": [],
   "source": [
    "data = '../data/simulated/sin_hawkes/'\n",
    "batch_size = 1\n",
    "\n",
    "# kernel = rational_quadratic_kernel(1,1)\n",
    "\n",
    "train_data, num_types = load_data(data + 'train.pkl', 'train')\n",
    "dev_data, _ = load_data(data + 'dev.pkl', 'dev')\n",
    "test_data, _ = load_data(data + 'test.pkl', 'test')\n",
    "t_max = 1\n",
    "\n",
    "trainloader = get_dataloader(train_data, 20, shuffle=False,t_max =t_max)\n",
    "testloader = get_dataloader(test_data,40, shuffle=False,t_max = t_max)\n",
    "valloader = get_dataloader(dev_data,40, shuffle=False,t_max =t_max)\n",
    "\n",
    "\n",
    "valid_events = 0\n",
    "test_events = 0\n",
    "train_events = 0\n",
    "for seq in valloader.dataset.event_type:\n",
    "    valid_events += len(seq)\n",
    "for seq in trainloader.dataset.event_type:\n",
    "    train_events += len(seq)\n",
    "for seq in testloader.dataset.event_type:\n",
    "    test_events  += len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:20:10.593222Z",
     "start_time": "2021-10-09T22:20:06.592573Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, NLL:9.886042\n",
      "omega:0.586136\n",
      "s:1.106126\n",
      "Base_intensity:0.144395\n",
      "\n",
      "Epoch:1, NLL:9.684965\n",
      "omega:0.589240\n",
      "s:1.099218\n",
      "Base_intensity:0.134765\n",
      "\n",
      "Epoch:2, NLL:9.485313\n",
      "omega:0.592320\n",
      "s:1.092364\n",
      "Base_intensity:0.125514\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c66ae34525a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mepoch_loss\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class rayleigh_kernel(nn.Module):\n",
    "\n",
    "    def __init__(self,sigma=1,alpha=1,lengthscale = 1.0,base_intensity =0.2):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        If the model is 1-D we still need the type embedding as an input and train a linear layer followed by softplus\n",
    "        to make sure the length_scale parameter is positive. Adding a parameter followed by a sigmoid creates a non leaf\n",
    "        tensor and there for doesn't work.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "        self.omega = torch.nn.Parameter(torch.randn(1))\n",
    "        self.base_intensity = torch.nn.Parameter(torch.randn(1))\n",
    "        self.s = torch.nn.Parameter(torch.randn(1))\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        base_intensity = F.softplus(self.base_intensity,beta = 10)\n",
    "        s = F.softplus(self.s,beta = 0.7)\n",
    "        omega = torch.sigmoid(self.omega)\n",
    "\n",
    "        \n",
    "        \n",
    "        d = torch.abs(x[0] - x[1])\n",
    "        self.scores = omega*d*torch.exp(-omega*d/s**2)\n",
    "        \n",
    "        \n",
    "\n",
    "#         self.scores = (self.sigma ** 2) * (1 + (d ** 2) / (self.alpha * self.lengthscale ** 2)) ** (-self.alpha)\n",
    "\n",
    "        return self.scores\n",
    "\n",
    "    def integral(self,x):\n",
    "        \n",
    "        s = F.softplus(self.s,beta = 0.7)\n",
    "\n",
    "        omega = torch.sigmoid(self.omega)\n",
    "\n",
    "        a = (s**2)\n",
    "        b = torch.exp(-(omega*s)/(x+1e-6)**2)\n",
    "        c = (s**2+omega*x)\n",
    "        return (a*b*c)/omega\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "epoch_losses = []\n",
    "\n",
    "\n",
    "kernel = rayleigh_kernel(sigma = 0.6, lengthscale=0.7, base_intensity= 0.1)\n",
    "optimizer = optim.Adam(filter(lambda x: x.requires_grad, kernel.parameters()),\n",
    "                      0.00005, betas=(0.9, 0.999), eps=1e-05, weight_decay=0.0)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for batch in trainloader:\n",
    "        event_time, arrival_time, event_type, _ = map(lambda x: x.to('cpu'), batch)\n",
    "\n",
    "        lengths = (event_type != 0).sum(-1).to('cpu')\n",
    "        xt_bar = event_time.unsqueeze(1). \\\n",
    "            expand(event_time.size(0), event_time.size(1), event_time.size(1))\n",
    "        xt = xt_bar.transpose(1, 2)\n",
    "        scores = kernel((xt_bar,xt))\n",
    "\n",
    "        n_batch = xt.size()[0]\n",
    "        length= xt.size()[1]\n",
    "\n",
    "\n",
    "        base_intensity = F.softplus(kernel.base_intensity,beta = 10)\n",
    "        s = F.softplus(kernel.s,beta = 0.7)\n",
    "        omega = torch.sigmoid(kernel.omega)\n",
    "\n",
    "\n",
    "        ## Log Sum Intensities\n",
    "\n",
    "        scores_0 = kernel((torch.ones(n_batch,length),torch.ones(n_batch,length)))\n",
    "        intensities =scores \n",
    "\n",
    "        subsequent_mask=get_subsequent_mask(event_type)\n",
    "        intensities = intensities.masked_fill_(subsequent_mask == 0, value=0)\n",
    "        sample_intensities = intensities.sum(-1)-scores_0+base_intensity\n",
    "        log_sum_intensities =nn.utils.rnn.pack_padded_sequence(sample_intensities.T, lengths - 1, enforce_sorted=False)[0].log().sum(-1)\n",
    "\n",
    "\n",
    "        ## Non Event Intensities Integral\n",
    "\n",
    "        t_start = event_time[:,0]\n",
    "        t_end =  event_time.max(-1)[0]\n",
    "\n",
    "\n",
    "        constant_part = (sample_intensities[:,:-1]*arrival_time[:,1:]).sum(-1)\n",
    "\n",
    "        functional_part =kernel.integral(arrival_time[:,1:]).sum(-1)\n",
    "        non_event_intensities = constant_part+functional_part +torch.abs((t_start - t_end)*base_intensity)\n",
    "\n",
    "        batch_loss = -(log_sum_intensities - non_event_intensities.sum())\n",
    "        epoch_loss+=batch_loss\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    epoch_loss = (epoch_loss/train_events).item()\n",
    "    print(f'Epoch:{epoch}, NLL:{epoch_loss:.6f}')\n",
    "    print(f'omega:{omega.item():.6f}')\n",
    "    print(f's:{s.item():.6f}')\n",
    "    print(f'Base_intensity:{base_intensity.item():.6f}\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "    epoch_losses.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T21:11:48.489609Z",
     "start_time": "2021-10-06T21:11:48.472687Z"
    }
   },
   "outputs": [],
   "source": [
    "x = arrival_time[:,1:]\n",
    "omega = F.softplus(kernel.omega,beta =1)\n",
    "a = (s**2)\n",
    "b = torch.exp(-(omega*s)/x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T21:11:51.563225Z",
     "start_time": "2021-10-06T21:11:51.546318Z"
    }
   },
   "outputs": [],
   "source": [
    " b = -(omega*s)/x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T21:11:53.528203Z",
     "start_time": "2021-10-06T21:11:53.521204Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2908e-01, -5.4327e-02, -9.5139e-02,  ..., -1.2311e-01,\n",
       "         -6.7911e+01, -2.5823e-01],\n",
       "        [-2.0101e+01, -4.6918e-03, -7.5552e-03,  ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        [-8.4493e-03, -1.6205e-03, -6.6116e-02,  ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        ...,\n",
       "        [-1.7616e+00, -5.4808e-01, -4.5753e+02,  ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        [-1.1879e+00, -3.1272e-01, -4.6402e+02,  ...,        -inf,\n",
       "                -inf,        -inf],\n",
       "        [-2.9649e+01, -7.3931e+01, -1.3559e+00,  ...,        -inf,\n",
       "                -inf,        -inf]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-06T21:10:42.621773Z",
     "start_time": "2021-10-06T21:10:42.616787Z"
    }
   },
   "source": [
    "## Getting the log likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T00:38:50.753945Z",
     "start_time": "2021-10-10T00:38:50.718041Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data_loaders(data_path = '../data/simulated/power_hawkes/',batch_size = 40):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_data, num_types = load_data(data_path + 'train.pkl', 'train')\n",
    "    dev_data, _ = load_data(data_path + 'dev.pkl', 'dev')\n",
    "    test_data, _ = load_data(data_path + 'test.pkl', 'test')\n",
    "\n",
    "    trainloader = get_dataloader(train_data, batch_size, shuffle=False,t_max =1)\n",
    "    testloader = get_dataloader(test_data,batch_size, shuffle=False,t_max = 1)\n",
    "    valloader = get_dataloader(dev_data,batch_size, shuffle=False,t_max =1)\n",
    "\n",
    "\n",
    "    valid_events = 0\n",
    "    test_events = 0\n",
    "    train_events = 0\n",
    "\n",
    "    for seq in valloader.dataset.event_type:\n",
    "        valid_events += len(seq)\n",
    "    for seq in trainloader.dataset.event_type:\n",
    "        train_events += len(seq)\n",
    "    for seq in testloader.dataset.event_type:\n",
    "        test_events  += len(seq)\n",
    "\n",
    "    return (trainloader,valloader,testloader,train_events,valid_events,test_events)\n",
    "\n",
    "\n",
    "class magic_kernel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_types=1, d_type=1, sigma=1, p=1, alpha=1, lengthscale=1.0, betas=[5, 1, 1]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_type = d_type\n",
    "        self.num_types = num_types\n",
    "        self.norm = p\n",
    "        self.param_loss = 0\n",
    "        self.scores = None\n",
    "        self.sigma = sigma\n",
    "        self.alpha = alpha\n",
    "        self.lengthscale = lengthscale\n",
    "        self.betas = betas\n",
    "\n",
    "        \"\"\"\n",
    "        If the model is 1-D we still need the type embedding as an input and train a linear layer followed by softplus\n",
    "        to make sure the length_scale parameter is positive. Adding a parameter followed by a sigmoid creates a non leaf\n",
    "        tensor and there for doesn't work.\n",
    "        \"\"\"\n",
    "\n",
    "#         if num_types == 1:\n",
    "\n",
    "#             self.lengthscale = torch.nn.Parameter(torch.randn(1))\n",
    "# #             self.base_intensity = torch.nn.Parameter(torch.randn(1))\n",
    "#             self.base_intensity =torch.tensor(-2.3)\n",
    "#             self.sigma = torch.nn.Parameter(torch.randn(1))\n",
    "#             self.alpha = torch.nn.Parameter(torch.randn(1))\n",
    "\n",
    "#         else:\n",
    "#             self.lengthscale = nn.Sequential(nn.Linear(d_type * 2, 1, bias=False), nn.Softplus(beta = 10))\n",
    "#             self.alpha = nn.Sequential(nn.Linear(d_type * 2, 1, bias=False), nn.Softplus(beta = 1))\n",
    "#             self.sigma = nn.Sequential(nn.Linear(d_type * 2, 1, bias=False), nn.Sigmoid())\n",
    "#             self.base_intensity = nn.Sequential(nn.Linear(d_type, 1, bias=False), nn.Softplus())\n",
    "\n",
    "    def forward(self, time_diff, combined_embeddings=None,non_event_intensity = False)  :      \n",
    "\n",
    "        lengthscale = self.lengthscale\n",
    "        sigma = self.sigma\n",
    "        alpha = self.alpha        \n",
    "        d = time_diff\n",
    "\n",
    "#         if self.num_types == 1:\n",
    "# #             lengthscale = F.softplus(self.lengthscale)\n",
    "# #             sigma = torch.sigmoid(self.sigma)      \n",
    "# #             alpha = F.softplus(self.alpha)\n",
    "# #             base_intensity = F.softplus(self.base_intensity)\n",
    "\n",
    "#         else:\n",
    "#             if not non_event_intensity:\n",
    "#                 lengthscale = self.lengthscale(combined_embeddings).squeeze(-1)\n",
    "#                 sigma = self.sigma(combined_embeddings).squeeze(-1)\n",
    "#                 alpha = self.alpha(combined_embeddings).squeeze(-1)\n",
    "\n",
    "#             else:\n",
    "#                 lengthscale = self.lengthscale(combined_embeddings)\n",
    "#                 sigma = self.sigma(combined_embeddings)\n",
    "#                 alpha = self.alpha(combined_embeddings)\n",
    "\n",
    "#             base_intensity = self.base_intensity(combined_embeddings[:, :, :, self.d_type:]).squeeze(-1)\n",
    "\n",
    "        # (sigma ** 2) * (1 + (d ** 2) / (self.alpha * lengthscale ** 2)) ** (-self.alpha)\n",
    "        #\n",
    "        # (sigma ** 2) * (1 + (d ** 2) / (self.alpha * lengthscale ** 2)) ** (-self.alpha) *((1 + torch.exp(-d)) ** -alpha)\n",
    "        self.scores = sigma * torch.exp(-d / lengthscale) * ((1 + torch.exp(-d)) ** -alpha)\n",
    "        # self.scores = (sigma ** 2) * (1 + (d ** 2) / (1 * lengthscale ** 2)) ** (-1) *((1 + torch.exp(-d)) ** -alpha)\n",
    "\n",
    "        return self.scores\n",
    "    \n",
    "    \n",
    "def get_sample_intensities(kernel,event_time, arrival_time, event_type, device='cpu', embeddings=None,base_intensity=0.1):\n",
    "\n",
    "    # event_time, arrival_time, event_type, _ = map(lambda x: x.to(device), batch)\n",
    "\n",
    "    xt_bar, xt = get_pairwise_times(event_time)\n",
    "    t_diff = torch.abs(xt_bar - xt)\n",
    "    n_batch = t_diff.size()[0]\n",
    "    length_batch = t_diff.size()[1]\n",
    "\n",
    "    if kernel.num_types == 1:\n",
    "        scores = kernel(t_diff)\n",
    "        scores_0 = kernel(torch.zeros(n_batch, length_batch).to(device))  # We need this to get actual intensities\n",
    "  \n",
    "    else:\n",
    "\n",
    "        pair_wise_embeddings = get_pairwise_type_embeddings(embeddings)\n",
    "        combined_embeddings = torch.cat([pair_wise_embeddings[0], pair_wise_embeddings[1]],\n",
    "                                        dim=-1)  # Last Part is the current event\n",
    "        scores = kernel(t_diff, combined_embeddings)\n",
    "        scores_0 = kernel(torch.zeros(n_batch, length_batch, length_batch).to(device),\n",
    "                          combined_embeddings)  # We need this to get actual intensities\n",
    "        scores_0 = torch.diagonal(scores_0, dim1=1, dim2=-1)\n",
    "\n",
    "    subsequent_mask = get_subsequent_mask(event_type)\n",
    "    sample_intensities = scores.masked_fill_(subsequent_mask == 0, value=0).sum(-1)\n",
    "\n",
    "    sample_intensities = scores.sum(-1) - scores_0\n",
    "    seq_length_mask = (event_type != 0) * 1\n",
    "\n",
    "    return (sample_intensities + base_intensity) * seq_length_mask\n",
    "\n",
    "\n",
    "def get_non_event_intensities(kernel,  event_time, arrival_time, event_type,\n",
    "                              type_embeddings=None, device='cpu',mc_sample_size = 5,base_intensity =  0.1,base_intensities = None):\n",
    "\n",
    "    # event_time, arrival_time, event_type, _ = map(lambda x: x.to(device), batch)\n",
    "\n",
    "    sample_arrival_time = arrival_time[:, 1:]\n",
    "    sample_event_time = event_time[:, :-1]\n",
    "    t_last = sample_event_time.max(-1)[0]\n",
    "    n_batch = sample_arrival_time.size(0)\n",
    "    n_t = sample_arrival_time.size(1)\n",
    "\n",
    "    mc_values = torch.rand((n_batch, n_t, mc_sample_size)).to(device) * \\\n",
    "                sample_arrival_time.unsqueeze(-1) + sample_event_time.unsqueeze(-1)\n",
    "\n",
    "    samples = sample_event_time.unsqueeze(-1).expand((n_batch, n_t, mc_sample_size))\n",
    "    samples = samples.unsqueeze(1).expand(samples.size(\n",
    "        0), samples.size(1), samples.size(1), samples.size(-1))\n",
    "\n",
    "    mc_values_bar = mc_values.unsqueeze(1).expand(mc_values.size(\n",
    "        0), mc_values.size(1), mc_values.size(1), mc_values.size(-1))\n",
    "\n",
    "    mc_values_bar = mc_values_bar.transpose(1, 2)\n",
    "    d = torch.abs((mc_values_bar - samples))\n",
    "\n",
    "    if kernel.num_types == 1:\n",
    "\n",
    "        non_event_intensities = kernel(d)\n",
    "        trigger_integral = non_event_intensities.mean(-1)\n",
    "        subsequent_mask = get_subsequent_mask(event_type[:, 1:])\n",
    "        integral = trigger_integral * subsequent_mask\n",
    "        integral = integral.sum(-1)\n",
    "        seq_length_mask = (event_type[:, 1:] != 0) * 1\n",
    "        integral = integral * seq_length_mask\n",
    "#         base_intensity = F.softplus(kernel.base_intensity, beta=1)\n",
    "        base_intensity = base_intensity\n",
    "\n",
    "        sequence_integral =integral.sum(-1)+base_intensity*t_last\n",
    "    else:\n",
    "        sequence_integral = 0\n",
    "        for i in range(kernel.num_types):\n",
    "            sample_event_types = event_type[:, 1:]\n",
    "            sample_embeddings = type_embeddings(sample_event_types)\n",
    "            xd_bar = sample_embeddings.unsqueeze(1).expand(sample_embeddings.size(\n",
    "                0), sample_embeddings.size(1), sample_embeddings.size(1), sample_embeddings.size(-1))\n",
    "\n",
    "            current_embedding = type_embeddings(torch.tensor([i]).to(device))\n",
    "            current_embedding = current_embedding[:, None, None:].expand(xd_bar.size()).transpose(1, 2)\n",
    "            combined_embeddings = torch.cat([xd_bar, current_embedding], dim=-1)\n",
    "\n",
    "            non_event_intensities = kernel(d, combined_embeddings, non_event_intensity=True)\n",
    "            trigger_integral = non_event_intensities.mean(-1)\n",
    "            subsequent_mask = get_subsequent_mask(sample_event_types)\n",
    "            integral = trigger_integral * subsequent_mask\n",
    "            integral = integral.sum(-1)\n",
    "            seq_length_mask = (event_type[:, 1:] != 0) * 1\n",
    "            integral = integral * seq_length_mask\n",
    "#             base_intensity = kernel.base_intensity(type_embeddings(torch.tensor([i]).to(device)))\n",
    "            base_intensity = base_intensities[i]\n",
    "            sequence_integral += integral.sum(-1) + base_intensity * t_last\n",
    "\n",
    "    return sequence_integral\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T02:29:14.161402Z",
     "start_time": "2021-10-10T02:29:14.154453Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "num_types = 2\n",
    "type_embeddings = nn.Embedding(num_types + 1, dtype, padding_idx=0).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T00:37:26.696391Z",
     "start_time": "2021-10-10T00:37:26.670461Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sigmoid(): argument 'input' (position 1) must be Tensor, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-c45a14b04271>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sigmoid(): argument 'input' (position 1) must be Tensor, not int"
     ]
    }
   ],
   "source": [
    "torch.sigmoid(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T02:28:33.956389Z",
     "start_time": "2021-10-10T02:28:32.526565Z"
    }
   },
   "outputs": [],
   "source": [
    "sigmas = [0.1,0.7,1.0]\n",
    "lengthscales = [0.1,1.0,2.0]\n",
    "alphas = []\n",
    "base_intensities = np.linspace(0,1,10)\n",
    "\n",
    "\n",
    "\n",
    "kernel = kernel_functions.magic_kernel(2,sigma=0.5, alpha=1.0 , lengthscale=1.3).to(device)\n",
    "\n",
    "trainloader,valloader,testloader,train_events,valid_events,test_events = load_data_loaders(data_path = '../data/simulated/sin_hawkes/',batch_size = 40)\n",
    "total_loss =0\n",
    "for batch in trainloader:\n",
    "    batch\n",
    "#     event_time, arrival_time, event_type, _ = map(lambda x: x.to(device), batch)\n",
    "#     sample_intensities = kernel_functions.get_sample_intensities(kernel,event_time, arrival_time, event_type,\n",
    "#                                                      device=device, embeddings=type_embeddings,base_intensity = 0.2)\n",
    "#     sample_intensities[sample_intensities==0] =1\n",
    "#     sample_intensities = sample_intensities.log().sum(-1)\n",
    "#     non_event_intensities = get_non_event_intensities(kernel,  event_time, arrival_time,\n",
    "#                                                                    event_type,\n",
    "#                           type_embeddings=type_embeddings, device=device,mc_sample_size = 5,base_intensity = 0.2)\n",
    "#     nll_loss = -(sample_intensities-non_event_intensities).sum()\n",
    "#     total_loss+=nll_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T02:29:58.490301Z",
     "start_time": "2021-10-10T02:29:58.199631Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6990], device='cuda:0', grad_fn=<SoftplusBackward>)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.base_intensity(type_embeddings(torch.tensor(1).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T02:29:52.518555Z",
     "start_time": "2021-10-10T02:29:52.479659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0388,  0.8927, -2.1533,  1.2202,  0.2024,  0.4263,  0.3830,  0.8494,\n",
       "        -1.4979,  1.0359, -0.2364, -1.7491,  0.6800, -0.1618, -0.6520, -0.4840,\n",
       "        -0.3222, -0.6776,  0.1516,  1.1664, -0.0495,  0.5862, -1.9633, -1.0977,\n",
       "        -0.2065, -0.7687,  0.6140, -0.6840,  1.0882,  0.8283, -1.1135, -0.5497],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_embeddings(torch.tensor(1).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T00:55:38.478251Z",
     "start_time": "2021-10-10T00:55:38.472268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(365150.4688, device='cuda:0')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T00:56:21.575929Z",
     "start_time": "2021-10-10T00:56:21.557977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(351932.0625, device='cuda:0')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T00:56:33.633176Z",
     "start_time": "2021-10-10T00:56:33.624203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(342955.5000, device='cuda:0')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T00:12:25.925393Z",
     "start_time": "2021-10-10T00:12:25.917406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.3000)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel.base_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T00:15:33.023265Z",
     "start_time": "2021-10-10T00:15:33.011297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0955)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softplus(torch.tensor(-2.3), beta=kernel.betas[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-10T00:01:38.550008Z",
     "start_time": "2021-10-10T00:01:38.538993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.3000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T23:45:24.036382Z",
     "start_time": "2021-10-09T23:45:24.009454Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-ef411d3c4bf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevent_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marrival_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m sample_intensities = kernel_functions.get_sample_intensities(self.encoder.kernel,event_time, batch_arrival_times, batch_types,\n",
      "\u001b[1;32m<ipython-input-51-ef411d3c4bf7>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevent_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marrival_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m sample_intensities = kernel_functions.get_sample_intensities(self.encoder.kernel,event_time, batch_arrival_times, batch_types,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sample_intensities = kernel_functions.get_sample_intensities(self.encoder.kernel,event_time, batch_arrival_times, batch_types,\n",
    "                                                             device=device, embeddings=embeddings)\n",
    "sample_intensities = sample_intensities.sum(-1)\n",
    "non_event_intensities = kernel_functions.get_non_event_intensities(self.encoder.kernel,  event_time, batch_arrival_times,\n",
    "                                                                   batch_types,\n",
    "                      type_embeddings=self.encoder.type_emb, device=device,mc_sample_size = 5)\n",
    "nll_loss = -(sample_intensities-non_event_intensities).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T23:07:44.708095Z",
     "start_time": "2021-10-09T23:07:41.478310Z"
    }
   },
   "outputs": [],
   "source": [
    "event_time, arrival_time, event_type, _ = map(lambda x: x.to(device), batch)\n",
    "embeddings = type_embeddings(event_type)\n",
    "sample_intensities = kernel_functions.get_sample_intensities(kernel,batch,device= device,embeddings =embeddings)\n",
    "non_event_intensities =get_non_event_intensities(kernel, batch,type_embeddings=type_embeddings, device='cpu',mc_sample_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T23:08:12.328528Z",
     "start_time": "2021-10-09T23:08:12.316560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1426, 0.6352, 0.6384, 1.1430, 1.1426, 1.1557, 1.3196, 0.6404, 0.9150,\n",
       "        0.6348, 0.8168, 1.1452, 1.4838, 1.9160, 1.6435, 1.2997, 1.2121, 0.9370,\n",
       "        1.5060, 0.8490, 1.8299, 1.5522, 1.6921, 1.5630, 2.0960, 1.2370, 1.2769,\n",
       "        1.6783, 1.7655, 0.8479, 1.1426, 0.8833, 2.0595, 1.9876, 2.3234, 2.7976,\n",
       "        0.6348, 1.0404, 2.0586, 1.1432, 1.4328, 0.7026, 0.6850, 1.7039, 1.1441,\n",
       "        1.2505, 1.1796, 1.1190, 1.6459, 2.0817, 0.7079, 0.6351, 0.6698, 0.7811,\n",
       "        1.7351, 2.4722, 2.1004, 2.4733, 2.0668, 3.4276, 1.2506, 0.6412, 0.9228,\n",
       "        1.2614, 0.6752, 1.1738, 0.8629, 2.0139, 2.5608, 1.4336, 2.5385, 2.1294,\n",
       "        1.1210, 1.4485, 1.2259, 0.6360, 1.1172, 0.6778, 0.6365, 0.6602, 1.8127,\n",
       "        1.2822, 1.9790, 0.9001, 1.1086, 1.5179, 1.2142, 2.3429, 1.3730, 1.9425,\n",
       "        1.3102, 2.2970, 3.0335, 1.1996, 1.6552, 1.7434, 0.6350, 1.6496, 2.0652,\n",
       "        1.6581, 1.1713, 1.2430, 0.7974, 0.6453, 1.1760, 1.7805, 2.2146, 0.7789,\n",
       "        1.3991, 0.7759, 1.9977, 1.6216, 1.4193, 1.1358, 1.6022, 2.1786, 2.5057,\n",
       "        1.9925, 3.4981, 1.7292, 2.2626, 2.4647, 2.8050, 2.0068, 3.0452, 3.5000,\n",
       "        1.8355, 0.9843, 1.4438, 2.0353, 1.2824, 0.7635, 1.3421, 1.1678, 1.1528,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_intensities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T23:07:49.787224Z",
     "start_time": "2021-10-09T23:07:49.773262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 461.1487,  587.7064,  507.8156,  607.8556,  496.6086,  646.5068,\n",
       "         1034.2786,  706.8341,  582.9006,  805.8822,  406.0864,  711.5400,\n",
       "          608.1233,  451.5201,  771.9742,  502.5106,  588.0792,  518.2933,\n",
       "          379.4916,  570.9720,  618.3298,  586.9587,  462.9715,  663.7072,\n",
       "          482.9331,  500.2524,  805.8136,  540.2129,  583.9819,  597.1379,\n",
       "          425.7408,  633.5850,  585.1597,  521.8990,  747.3402,  638.8920,\n",
       "          488.0743,  451.7670,  484.7585,  604.8957]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_event_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:20:17.820324Z",
     "start_time": "2021-10-09T22:20:17.806361Z"
    }
   },
   "outputs": [],
   "source": [
    "event_time, arrival_time, event_type, _ = map(lambda x: x.to(device), batch)\n",
    "mc_sample_size = 2\n",
    "sample_arrival_time = arrival_time[:,1:]\n",
    "sample_event_time = event_time[:,:-1]\n",
    "t_last = sample_event_time.max(-1)[0]\n",
    "n_batch = sample_arrival_time.size(0)\n",
    "n_t = sample_arrival_time.size(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:20:19.722659Z",
     "start_time": "2021-10-09T22:20:19.713699Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_values = torch.rand((n_batch,n_t,mc_sample_size)).to(device)*sample_arrival_time.unsqueeze(-1) +event_time[:,:-1].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:20:20.158732Z",
     "start_time": "2021-10-09T22:20:20.142741Z"
    }
   },
   "outputs": [],
   "source": [
    "samples = sample_event_time.unsqueeze(-1).expand((n_batch,n_t,mc_sample_size))\n",
    "samples = samples.unsqueeze(1).expand(samples.size(\n",
    "        0), samples.size(1), samples.size(1), samples.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:20:20.644665Z",
     "start_time": "2021-10-09T22:20:20.639678Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_values_bar = mc_values.unsqueeze(1).expand(mc_values.size(\n",
    "        0), mc_values.size(1), mc_values.size(1), mc_values.size(-1))\n",
    "\n",
    "mc_values_bar = mc_values_bar.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:20:21.660806Z",
     "start_time": "2021-10-09T22:20:21.616925Z"
    }
   },
   "outputs": [],
   "source": [
    "d = torch.abs((mc_values_bar - samples))\n",
    "\n",
    "# non_event_intensities = kernel(d)\n",
    "# trigger_integrals = non_event_intensities.mean(-1)\n",
    "# subsequent_mask = get_subsequent_mask(event_type[:,1:])\n",
    "# integral = trigger_integral*subsequent_mask\n",
    "# integral = integral.sum(-1)\n",
    "# seq_length_mask = (event_type[:,1:] != 0) * 1\n",
    "# integral = integral*seq_length_mask\n",
    "\n",
    "# base_intensity = F.softplus(kernel.base_intensity, beta=1)\n",
    "\n",
    "# sequence_integral =integral.sum(-1)+base_intensity*t_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:32:56.570265Z",
     "start_time": "2021-10-09T22:32:56.560247Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 331])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_time[:-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:33:12.256165Z",
     "start_time": "2021-10-09T22:33:12.235225Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_arrival_time = arrival_time[:, 1:]\n",
    "sample_event_time = event_time[:, :-1]\n",
    "t_last = sample_event_time.max(-1)[0]\n",
    "n_batch = sample_arrival_time.size(0)\n",
    "\n",
    "n_t = sample_arrival_time.size(1)\n",
    "\n",
    "mc_values = torch.rand((n_batch, n_t, 2)).to(device) * \\\n",
    "            sample_arrival_time.unsqueeze(-1) +sample_event_time.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:20:22.619712Z",
     "start_time": "2021-10-09T22:20:22.603756Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_types = type_embeddings(torch.tensor([range(1,num_types+1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:34:15.244479Z",
     "start_time": "2021-10-09T22:34:15.213558Z"
    }
   },
   "outputs": [],
   "source": [
    "compensator =get_non_event_intensities(kernel, batch,type_embeddings=type_embeddings, device='cpu',mc_sample_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:34:16.510878Z",
     "start_time": "2021-10-09T22:34:16.490932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 99.6408,  88.0461,  96.3559,  98.2445,  98.3215,  85.4530, 105.7602,\n",
       "         94.5943,  91.9119,  99.1646,  92.3523,  95.8380,  93.0733,  94.8377,\n",
       "         92.8882,  86.0339,  88.0227,  91.5060,  96.5376,  96.7593,  96.2483,\n",
       "         91.1681,  89.7881,  93.1762,  97.8715,  91.2969,  91.7242,  89.0858,\n",
       "         98.3729,  99.1456,  96.3078,  95.1227,  94.7207,  92.0839,  88.7675,\n",
       "         97.9171,  95.1148,  86.1241,  93.4037,  94.5680],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compensator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:33:37.730720Z",
     "start_time": "2021-10-09T22:33:37.706821Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_non_event_intensities(kernel, batch,type_embeddings=None, device='cpu',mc_sample_size = 5):\n",
    "\n",
    "    event_time, arrival_time, event_type, _ = map(lambda x: x.to(device), batch)\n",
    "\n",
    "    sample_arrival_time = arrival_time[:, 1:]\n",
    "    sample_event_time = event_time[:, :-1]\n",
    "    t_last = sample_event_time.max(-1)[0]\n",
    "    n_batch = sample_arrival_time.size(0)\n",
    "    n_t = sample_arrival_time.size(1)\n",
    "\n",
    "    mc_values = torch.rand((n_batch, n_t, mc_sample_size)).to(device) * \\\n",
    "                sample_arrival_time.unsqueeze(-1) + sample_event_time.unsqueeze(-1)\n",
    "\n",
    "    samples = sample_event_time.unsqueeze(-1).expand((n_batch, n_t, mc_sample_size))\n",
    "    samples = samples.unsqueeze(1).expand(samples.size(\n",
    "        0), samples.size(1), samples.size(1), samples.size(-1))\n",
    "\n",
    "    mc_values_bar = mc_values.unsqueeze(1).expand(mc_values.size(\n",
    "        0), mc_values.size(1), mc_values.size(1), mc_values.size(-1))\n",
    "\n",
    "    mc_values_bar = mc_values_bar.transpose(1, 2)\n",
    "    d = torch.abs((mc_values_bar - samples))\n",
    "\n",
    "\n",
    "    if kernel.num_types == 1:\n",
    "\n",
    "        non_event_intensities = kernel(d)\n",
    "        trigger_integral = non_event_intensities.mean(-1)\n",
    "        subsequent_mask = get_subsequent_mask(event_type[:, 1:])\n",
    "        integral = trigger_integral * subsequent_mask\n",
    "        integral = integral.sum(-1)\n",
    "        seq_length_mask = (event_type[:, 1:] != 0) * 1\n",
    "        integral = integral * seq_length_mask\n",
    "        base_intensity = F.softplus(kernel.base_intensity, beta=1)\n",
    "        sequence_integral =integral.sum(-1)+base_intensity*t_last\n",
    "    else:\n",
    "        sequence_integral = 0\n",
    "        for i in range(kernel.num_types):\n",
    "            sample_event_types = event_type[:, 1:]\n",
    "            sample_embeddings = type_embeddings(sample_event_types)\n",
    "            xd_bar = sample_embeddings.unsqueeze(1).expand(sample_embeddings.size(\n",
    "                0), sample_embeddings.size(1), sample_embeddings.size(1), sample_embeddings.size(-1))\n",
    "\n",
    "            current_embedding = type_embeddings(torch.tensor([i]))\n",
    "            current_embedding = current_embedding[:, None, None:].expand(xd_bar.size()).transpose(1, 2)\n",
    "            combined_embeddings = torch.cat([xd_bar, current_embedding], dim=-1)\n",
    "\n",
    "            non_event_intensities = kernel(d, combined_embeddings, non_event_intensity=True)\n",
    "            trigger_integral = non_event_intensities.mean(-1)\n",
    "            subsequent_mask = get_subsequent_mask(sample_event_types)\n",
    "            integral = trigger_integral * subsequent_mask\n",
    "            integral = integral.sum(-1)\n",
    "            seq_length_mask = (event_type[:, 1:] != 0) * 1\n",
    "            integral = integral * seq_length_mask\n",
    "            base_intensity = kernel.base_intensity(type_embeddings(torch.tensor([i])))\n",
    "            sequence_integral += integral.sum(-1) + base_intensity * t_last\n",
    "\n",
    "    return sequence_integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:27:24.873418Z",
     "start_time": "2021-10-09T22:27:24.857444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 607.7885,  778.3657,  657.0847,  753.1837,  626.2035,  808.7565,\n",
       "         1312.2151,  879.8285,  734.3093, 1039.9067,  548.0630,  877.4598,\n",
       "          775.4640,  579.8536, 1002.8474,  659.2673,  774.5371,  656.8925,\n",
       "          502.5174,  727.9685,  782.1413,  761.8102,  607.9001,  837.8970,\n",
       "          619.6664,  630.7327, 1004.1382,  702.7272,  727.8060,  756.7795,\n",
       "          566.8320,  801.7422,  770.1752,  660.1862,  910.5734,  859.7356,\n",
       "          631.0574,  579.2618,  614.3885,  768.2284]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:26:08.716797Z",
     "start_time": "2021-10-09T22:26:08.696850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[352.7889, 435.0499, 376.0016, 423.2532, 361.4338, 450.1643, 693.3066,\n",
       "         484.4462, 414.3322, 562.0352, 321.6632, 483.8730, 434.2220, 339.8895,\n",
       "         544.5463, 378.0758, 434.4902, 375.5476, 301.9268, 411.1165, 437.6788,\n",
       "         427.7701, 353.0417, 463.2853, 358.7669, 363.9360, 543.5995, 399.6214,\n",
       "         411.2084, 425.2991, 333.2314, 446.7322, 430.9052, 378.2196, 499.5726,\n",
       "         474.5798, 364.7369, 337.7893, 354.8994, 430.7442]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:26:16.641513Z",
     "start_time": "2021-10-09T22:26:16.617545Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[254.9995, 343.3158, 281.0830, 329.9305, 264.7697, 358.5922, 618.9084,\n",
       "         395.3822, 319.9771, 477.8715, 226.3997, 393.5868, 341.2419, 239.9641,\n",
       "         458.3011, 281.1916, 340.0469, 281.3448, 200.5905, 316.8519, 344.4625,\n",
       "         334.0402, 254.8584, 374.6116, 260.8994, 266.7967, 460.5387, 303.1058,\n",
       "         316.5977, 331.4805, 233.6007, 355.0100, 339.2700, 281.9666, 411.0008,\n",
       "         385.1558, 266.3205, 241.4725, 259.4891, 337.4842]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:25:05.004704Z",
     "start_time": "2021-10-09T22:25:04.984760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[352.7889, 435.0499, 376.0016, 423.2532, 361.4338, 450.1643, 693.3066,\n",
       "         484.4462, 414.3322, 562.0352, 321.6632, 483.8730, 434.2220, 339.8895,\n",
       "         544.5463, 378.0758, 434.4902, 375.5476, 301.9268, 411.1165, 437.6788,\n",
       "         427.7701, 353.0417, 463.2853, 358.7669, 363.9360, 543.5995, 399.6214,\n",
       "         411.2084, 425.2991, 333.2314, 446.7322, 430.9052, 378.2196, 499.5726,\n",
       "         474.5798, 364.7369, 337.7893, 354.8994, 430.7442]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_integral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:24:20.906963Z",
     "start_time": "2021-10-09T22:24:20.897988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[240.8670, 241.3226, 236.6862, 243.9725, 241.0291, 244.3786, 243.3094,\n",
       "         244.3111, 244.2222, 244.1342, 232.2904, 244.4065, 243.8047, 244.2902,\n",
       "         243.8539, 242.7897, 244.2795, 238.8226, 243.1743, 243.8973, 244.1301,\n",
       "         243.9728, 242.5198, 236.6412, 243.8182, 242.9477, 240.3951, 244.2452,\n",
       "         243.2847, 243.5173, 243.8977, 243.2151, 241.7991, 243.3204, 243.5927,\n",
       "         241.7718, 244.3802, 237.2125, 238.0700, 244.2785]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_intensity*t_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:16:06.461747Z",
     "start_time": "2021-10-09T22:16:06.431848Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (278784000x1 and 64x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-c7082d7b6048>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlengthscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_embeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1846\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1847\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1848\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (278784000x1 and 64x1)"
     ]
    }
   ],
   "source": [
    "kernel.lengthscale(combined_embeddings.unsqueeze(-1)).squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:15:42.026029Z",
     "start_time": "2021-10-09T22:15:41.927293Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (330) must match the size of tensor b (2) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-4495ec0e481e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlengthscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_embeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (330) must match the size of tensor b (2) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "kernel.lengthscale(combined_embeddings).squeeze(-1)*d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T22:15:08.301222Z",
     "start_time": "2021-10-09T22:15:08.282263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 330, 330, 2])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T10:06:25.958797Z",
     "start_time": "2021-10-09T10:06:25.923889Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_non_event_intensities(kernel,batch,sample_intensities,device = 'cpu',mc_sample_size = 10):\n",
    "    \n",
    "    event_time, arrival_time, event_type, _ = map(lambda x: x.to(device), batch)\n",
    "    \n",
    "    sample_arrival_time = arrival_time[:,1:]\n",
    "    sample_event_time = event_time[:,:-1]\n",
    "    t_last = sample_arrival_time.max(-1)[0]\n",
    "\n",
    "    n_batch = sample_arrival_time.size(0)\n",
    "    n_t = sample_arrival_time.size(1)\n",
    "    if kernel.num_types==1:\n",
    "        mc_values = torch.rand((n_batch,n_t,mc_sample_size)).to(device)*sample_arrival_time.unsqueeze(-1)\n",
    "        base_intensity  = F.softplus(kernel.base_intensity,beta = kernel.betas[-1])\n",
    "        seq_length_mask = (event_type[:,1:] != 0)*1\n",
    "        functional_part = kernel(mc_values).mean(-1)*seq_length_mask\n",
    "\n",
    "\n",
    "    else:\n",
    "        mc_values = torch.rand((n_batch,n_t,kernel.num_types,mc_sample_size)).to(device)*sample_arrival_time[:,:,None,None]\n",
    "        functional_part = kernel(mc_values)\n",
    "\n",
    "# #     constant_part = sample_intensities[:,:-1]*sample_arrival_time    \n",
    "    \n",
    "#     seq_length_mask = (event_type[:,1:] != 0)*1\n",
    "    \n",
    "    return functional_part\n",
    "\n",
    "\n",
    "def log_likelihood_loss(sample_intensities, non_event_intensities):\n",
    "    \n",
    "    sample_intensities[sample_intensities==0]=1\n",
    "    log_sum = sample_intensities.log().sum(-1)\n",
    "    \n",
    "    return -log_sum + non_event_intensities.sum(-1)\n",
    "\n",
    "\n",
    "\n",
    "def load_data_loaders(data_path = '../data/simulated/power_hawkes/',batch_size = 40):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train_data, num_types = load_data(data_path + 'train.pkl', 'train')\n",
    "    dev_data, _ = load_data(data_path + 'dev.pkl', 'dev')\n",
    "    test_data, _ = load_data(data_path + 'test.pkl', 'test')\n",
    "\n",
    "    trainloader = get_dataloader(train_data, batch_size, shuffle=False,t_max =1)\n",
    "    testloader = get_dataloader(test_data,batch_size, shuffle=False,t_max = 1)\n",
    "    valloader = get_dataloader(dev_data,batch_size, shuffle=False,t_max =1)\n",
    "\n",
    "\n",
    "    valid_events = 0\n",
    "    test_events = 0\n",
    "    train_events = 0\n",
    "\n",
    "    for seq in valloader.dataset.event_type:\n",
    "        valid_events += len(seq)\n",
    "    for seq in trainloader.dataset.event_type:\n",
    "        train_events += len(seq)\n",
    "    for seq in testloader.dataset.event_type:\n",
    "        test_events  += len(seq)\n",
    "\n",
    "    return (trainloader,valloader,testloader,train_events,valid_events,test_events)\n",
    "\n",
    "def train_model(model,trainloader,valloader,testloader,epochs = 250,lr = 0.0001):\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(filter(lambda x: x.requires_grad, model.parameters()),\n",
    "                          lr, betas=(0.9, 0.999), eps=1e-05, weight_decay=0.0)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch in trainloader:\n",
    "            sample_intensities = get_sample_intensities(model,batch,device = device)\n",
    "            non_event_intensities = get_non_event_intensities(model,batch,sample_intensities,device = device)\n",
    "            \n",
    "            reg_constant =(batch[2]!=0).sum()\n",
    "            \n",
    "            \n",
    "            ll_loss = log_likelihood_loss(sample_intensities,non_event_intensities)\n",
    "            loss = ll_loss.sum()-model.regularizer_loss()*reg_constant.item()\n",
    "\n",
    "\n",
    "            epoch_loss+=ll_loss.sum()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        epoch_loss = (epoch_loss/train_events).item()\n",
    "\n",
    "        lengthscale = F.softplus(model.lengthscale,beta = model.betas[0])\n",
    "        sigma = F.softplus(model.sigma,model.betas[1])\n",
    "        base_intensity = F.softplus(model.base_intensity,model.betas[2])\n",
    "        \n",
    "        print(f'Epoch:{epoch}, NLL:{epoch_loss:.6f}')\n",
    "        print(f'sigma:{sigma.item():.6f}')\n",
    "        print(f'lengthscale:{lengthscale.item():.6f}')\n",
    "        print(f'Base_intensity:{sigma.item():.6f}\\n')\n",
    "\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        \n",
    "    return model,epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T10:07:31.974014Z",
     "start_time": "2021-10-09T10:07:28.371098Z"
    }
   },
   "outputs": [],
   "source": [
    "## 2-D\n",
    "trainloader,valloader,testloader,train_events,valid_events,test_events = load_data_loaders(data_path = '../data/simulated/2_d_hawkes/',batch_size = 40)\n",
    "for batch in trainloader:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T10:07:32.778274Z",
     "start_time": "2021-10-09T10:07:32.754339Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'magic_kernel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-b5ac79f58209>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtype_emb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_types\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'magic_kernel' is not defined"
     ]
    }
   ],
   "source": [
    "num_types=2\n",
    "dtype=32\n",
    "kernel = magic_kernel(num_types,dtype)\n",
    "type_emb = nn.Embedding(num_types + 1, dtype, padding_idx=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T10:06:45.999962Z",
     "start_time": "2021-10-09T10:06:45.977056Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-97a032f846ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevent_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marrival_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_emb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msample_intensities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sample_intensities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "event_time, arrival_time, event_type, _ = map(lambda x: x.to(device), batch)\n",
    "embeddings = type_emb(event_type)\n",
    "sample_intensities = get_sample_intensities(kernel,batch,device= device,embeddings =embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T16:50:12.758376Z",
     "start_time": "2021-10-07T16:50:12.740393Z"
    }
   },
   "outputs": [],
   "source": [
    "mc = get_non_event_intensities(kernel,batch,sample_intensities,device = 'cpu',mc_sample_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T06:53:39.167824Z",
     "start_time": "2021-10-09T06:53:39.153862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.6656,  9.9690, 10.1388,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 6.4638,  7.2518,  8.1467,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [20.6661, 25.2682, 25.8075,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [59.9563, 72.5169, 73.3082,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [11.3614, 12.3198, 14.2027,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 1.9428, 17.4422, 21.1532,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 1030,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = 'cpu'\n",
    "\n",
    "trainloader,valloader,testloader,train_events,valid_events,test_events = load_data_loaders(data_path = '../data/simulated/2_d_hawkes/',batch_size = 40)\n",
    "for batch in trainloader:\n",
    "    event_time, arrival_time, event_type, _ = map(lambda x: x.to(device), batch)\n",
    "    \n",
    "\n",
    "num_types = 2\n",
    "dtype = 2\n",
    "\n",
    "type_embeddings = nn.Embedding(num_types + 1, dtype, padding_idx=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T06:53:48.694801Z",
     "start_time": "2021-10-09T06:53:48.680839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 1032,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T15:37:30.657478Z",
     "start_time": "2021-10-07T15:37:30.636569Z"
    }
   },
   "outputs": [],
   "source": [
    "subsequent_mask=get_subsequent_mask(event_type)\n",
    "scores = scores.masked_fill_(subsequent_mask == 0, value=0).sum(-1)\n",
    "scores_0 = torch.diagonal(scores_0,dim1=1, dim2=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T17:08:49.641162Z",
     "start_time": "2021-10-07T17:08:49.634152Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T17:10:33.913544Z",
     "start_time": "2021-10-07T17:10:32.772030Z"
    }
   },
   "outputs": [],
   "source": [
    "trainloader,valloader,testloader,train_events,valid_events,test_events = load_data_loaders(data_path = '../data/simulated/power_hawkes/',batch_size = 40)\n",
    "for batch in trainloader:\n",
    "    pass\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "model = magic_kernel(betas = beta_params,num_types=1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-09T06:02:22.308645Z",
     "start_time": "2021-10-09T06:02:22.265768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 1,  ..., 0, 0, 0],\n",
       "        [2, 2, 2,  ..., 0, 0, 0],\n",
       "        [2, 2, 2,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [2, 2, 2,  ..., 0, 0, 0],\n",
       "        [2, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 2, 2,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 1016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T17:10:34.431255Z",
     "start_time": "2021-10-07T17:10:34.408318Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_intensities = get_sample_intensities(model,batch,device= device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T17:11:44.659347Z",
     "start_time": "2021-10-07T17:11:44.651368Z"
    }
   },
   "outputs": [],
   "source": [
    "mc_val = get_non_event_intensities(model,batch,sample_intensities,device = 'cpu',mc_sample_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T17:11:45.362498Z",
     "start_time": "2021-10-07T17:11:45.350530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6778, 0.7117, 0.1134,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.6129, 0.5165, 0.6664,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.1852, 0.6690, 0.6931,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0696, 0.5887, 0.6811,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.5599, 0.3891, 0.0475,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0821, 0.3071, 0.5684,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 1013,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T06:52:13.415325Z",
     "start_time": "2021-10-07T06:52:13.399316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.0935, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_wise_embeddings[1].squeeze(-1)[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T09:12:11.817766Z",
     "start_time": "2021-10-07T09:12:10.826316Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (99) must match the size of tensor b (40) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-762-a23451936b8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbeta_params\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrational_quadratic_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbeta_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mlengthscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlengthscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbetas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftplus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbetas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-761-1b857691bf86>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, trainloader, valloader, testloader, epochs, lr)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m             \u001b[0mll_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_likelihood_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_intensities\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnon_event_intensities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mll_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregularizer_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mreg_constant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-761-1b857691bf86>\u001b[0m in \u001b[0;36mlog_likelihood_loss\u001b[1;34m(sample_intensities, non_event_intensities)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mlog_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_intensities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlog_sum\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnon_event_intensities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (99) must match the size of tensor b (40) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "epoch_losses = []\n",
    "trainloader,valloader,testloader,train_events,valid_events,test_events = load_data_loaders(data_path = '../data/simulated/power_hawkes/',batch_size = 40)\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "for lr in [0.0001,0.0005]:\n",
    "    for beta_params in [[1,1,1],[1,1,10],[1,1,5]]:\n",
    "        model = rational_quadratic_kernel(betas = beta_params,num_types=1).to(device)\n",
    "        model,loss = train_model(model,trainloader,valloader,testloader,epochs = 250,lr = lr)\n",
    "        lengthscale = F.softplus(model.lengthscale,beta = model.betas[0])\n",
    "        sigma = F.softplus(model.sigma,model.betas[1])\n",
    "        base_intensity = F.softplus(model.base_intensity,model.betas[2])\n",
    "\n",
    "        print(f'lr:{lr}, betas:{beta_params}, loss:{loss}')\n",
    "        print(f'sigma:{sigma.item():.6f}')\n",
    "        print(f'lengthscale:{lengthscale.item():.6f}')\n",
    "        print(f'Base_intensity:{base_intensity.item():.6f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T06:54:48.646064Z",
     "start_time": "2021-10-07T06:54:48.638071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0935, -1.0935], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T06:36:08.266494Z",
     "start_time": "2021-10-07T06:36:08.251534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.2181,  0.5232,  0.3466, -0.1973, -1.0546,  1.2780,  0.1453,  0.2311,\n",
       "         0.0566,  0.4263,  0.5750, -0.6417, -2.2064, -0.7508,  2.8140,  0.3598,\n",
       "        -1.3407, -0.5854,  0.5362,  0.5246,  1.1412,  0.0516,  0.7281, -0.7106,\n",
       "        -1.0495,  0.6039, -1.7223, -0.8278,  1.3347,  0.4835, -0.1976,  1.2683],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 551,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T06:35:01.449013Z",
     "start_time": "2021-10-07T06:35:01.427072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.2181,  0.5232,  0.3466, -0.1973, -1.0546,  1.2780,  0.1453,  0.2311,\n",
       "         0.0566,  0.4263,  0.5750, -0.6417, -2.2064, -0.7508,  2.8140,  0.3598,\n",
       "        -1.3407, -0.5854,  0.5362,  0.5246,  1.1412,  0.0516,  0.7281, -0.7106,\n",
       "        -1.0495,  0.6039, -1.7223, -0.8278,  1.3347,  0.4835, -0.1976,  1.2683],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_embeddings(event_type)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T05:49:00.116729Z",
     "start_time": "2021-10-07T05:48:59.955Z"
    }
   },
   "outputs": [],
   "source": [
    "t = torch.arange(0,200,0.1)\n",
    "\n",
    "values = model(t)\n",
    "values = (values - values.min())/(values.max()-values.min())\n",
    "real_values = power_law_kernel(t)\n",
    "real_values = (real_values - real_values.min())/(real_values.max()-real_values.min())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3,figsize=(17,4))\n",
    "\n",
    "\n",
    "for ax in axes:\n",
    "    ax.plot(t,values.detach(),label='Predicted')\n",
    "    ax.plot(t,real_values,label='Real')\n",
    "    ax.legend()\n",
    "    \n",
    "axes[0].set_xlim(0, 25)\n",
    "axes[1].set_xlim(0, 10)\n",
    "axes[2].set_xlim(0, 5)\n",
    "torch.abs(values -real_values).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-07T05:35:24.043525Z",
     "start_time": "2021-10-07T05:35:24.022593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000], device='cuda:0', grad_fn=<ClampBackward1>)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(model.sigma,min=0.5, max=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.sigma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
